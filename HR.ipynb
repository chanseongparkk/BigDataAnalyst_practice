{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a1tOk-uEjpMIg9SactD03KBnlz0qrqtG",
      "authorship_tag": "ABX9TyOpVoid1VC/8vxyC7dAUg8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanseongparkk/BigDataAnalyst_practise/blob/main/HR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-6ek7OK5NCQ",
        "outputId": "932ce976-87b0-4928-ec6d-9805ee42d8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/빅데이터분석기사 실기/HR\n"
          ]
        }
      ],
      "source": [
        "cd drive/My Drive/빅데이터분석기사 실기/HR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "\n",
        "X_train_id = X_train.iloc[:,0]\n",
        "X_test_id = X_test.iloc[:,0]\n",
        "y_train_id = y_train.iloc[:,0]\n",
        "\n",
        "X_train = X_train.iloc[:,1:]\n",
        "X_test = X_test.iloc[:,1:]\n",
        "y_train = y_train.iloc[:,1:]\n",
        "#print(X_train.info(),X_test.info(),y_train.info())\n",
        "\n",
        "### 결측치\n",
        "\n",
        "#print(X_train.isna().sum(), X_test.isna().sum(),X_train.shape,X_test.shape)\n",
        "\n",
        "# 결측치 많은 변수 날리기, 개체의 수가 많은 변수 날리기\n",
        "\n",
        "X_train = X_train.iloc[:,[1,3,4,5,7,10,11]]\n",
        "X_test = X_test.iloc[:,[1,3,4,5,7,10,11]]\n",
        "\n",
        "# print(X_train.shape,X_test.shape)\n",
        "\n",
        "### 결측치 대체\n",
        "\n",
        "#print(X_train.info(),X_test.info(),y_train.info())\n",
        "#print(X_train.describe(include = \"object\"),X_test.describe(include = \"object\"))\n",
        "X_train.enrolled_university = X_train.enrolled_university.fillna(\"no_enrollment\")\n",
        "X_train.education_level = X_train.education_level.fillna(\"Graduate\")\n",
        "X_train.experience = X_train.experience.fillna(\">20\")\n",
        "X_train.last_new_job = X_train.last_new_job.fillna(\"1\")\n",
        "X_test.enrolled_university = X_test.enrolled_university.fillna(\"no_enrollment\")\n",
        "X_test.education_level = X_test.education_level.fillna(\"Graduate\")\n",
        "X_test.experience = X_test.experience.fillna(\">20\")\n",
        "X_test.last_new_job = X_test.last_new_job.fillna(\"1\")\n",
        "\n",
        "### 변수 변환\n",
        "#print(X_train.info())\n",
        "#print(X_train.skew(),X_train.kurt(),\n",
        "#      np.log1p(X_train.iloc[:,[0,6]]).skew(),np.log1p(X_train.iloc[:,[0,6]]).kurt(),\n",
        "#      np.sqrt(X_train.iloc[:,[0,6]]).skew(),np.sqrt(X_train.iloc[:,[0,6]]).kurt())\n",
        "\n",
        "X_train.iloc[:,6] = np.log1p(X_train.iloc[:,6])\n",
        "X_test.iloc[:,6] = np.log1p(X_test.iloc[:,6])\n",
        "\n",
        "### 스케일러\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train.iloc[:,[0,6]] = scaler.fit_transform(X_train.iloc[:,[0,6]])\n",
        "X_test.iloc[:,[0,6]] = scaler.transform(X_test.iloc[:,[0,6]])\n",
        "\n",
        "#display(X_train.describe(include = \"object\"),X_test.describe(include = \"object\"))\n",
        "\n",
        "### 더미변수\n",
        "\n",
        "X_train = pd.get_dummies(X_train,drop_first = True)\n",
        "X_test = pd.get_dummies(X_test,drop_first = True)\n",
        "#print(X_train.shape,X_test.shape)\n",
        "#print(set(X_train.columns)-set(X_test.columns)) #변수 갯수 동일\n",
        "\n",
        "### 특수문자 들어간 변수 이름 바꾸기\n",
        "\n",
        "#print(X_train.columns)\n",
        "X_train.columns = ['city_development_index', 'training_hours',\n",
        "       'relevent_experience_No relevent experience',\n",
        "       'enrolled_university_Part time course',\n",
        "       'enrolled_university_no_enrollment', 'education_level_High School',\n",
        "       'education_level_Masters', 'education_level_Phd',\n",
        "       'education_level_Primary School', 'experience_10', 'experience_11',\n",
        "       'experience_12', 'experience_13', 'experience_14', 'experience_15',\n",
        "       'experience_16', 'experience_17', 'experience_18', 'experience_19',\n",
        "       'experience_2', 'experience_20', 'experience_3', 'experience_4',\n",
        "       'experience_5', 'experience_6', 'experience_7', 'experience_8',\n",
        "       'experience_9', 'experience_under1', 'experience_upper20', 'last_new_job_2',\n",
        "       'last_new_job_3', 'last_new_job_4', 'last_new_job_upper4',\n",
        "       'last_new_job_never']\n",
        "\n",
        "X_test.columns = ['city_development_index', 'training_hours',\n",
        "       'relevent_experience_No relevent experience',\n",
        "       'enrolled_university_Part time course',\n",
        "       'enrolled_university_no_enrollment', 'education_level_High School',\n",
        "       'education_level_Masters', 'education_level_Phd',\n",
        "       'education_level_Primary School', 'experience_10', 'experience_11',\n",
        "       'experience_12', 'experience_13', 'experience_14', 'experience_15',\n",
        "       'experience_16', 'experience_17', 'experience_18', 'experience_19',\n",
        "       'experience_2', 'experience_20', 'experience_3', 'experience_4',\n",
        "       'experience_5', 'experience_6', 'experience_7', 'experience_8',\n",
        "       'experience_9', 'experience_under1', 'experience_upper20', 'last_new_job_2',\n",
        "       'last_new_job_3', 'last_new_job_4', 'last_new_job_upper4',\n",
        "       'last_new_job_never']\n",
        "\n",
        "### 학습, 검증 데이터 분할\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 999)\n",
        "#print(X_train2.shape, X_val.shape, y_train2.shape, y_val.shape)\n",
        "\n",
        "\n",
        "### 모델링(RandomForestClassifier)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#rf = RandomForestClassifier(random_state = 999 )\n",
        "rf = RandomForestClassifier(n_estimators = 500, max_depth = 10, min_samples_split = 5, random_state = 999 )\n",
        "rf.fit(X_train2,y_train2)\n",
        "\n",
        "### 모델링(XGBClassifier)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimators = 500, max_depth = 10, subsample = 0.3, learning_rate = 0.05, random_state = 999)\n",
        "#xgb = XGBClassifier(random_state = 999)\n",
        "xgb.fit(X_train2,y_train2,eval_metric = \"auc\")\n",
        "\n",
        "print(\"rf train accuracy :\", rf.score(X_train2,y_train2),\"\\n\",\n",
        "      \"rf train roc_auc_score :\", roc_auc_score(y_train2,rf.predict(X_train2)),\"\\n\",\n",
        "      \"rf validation accuracy :\", rf.score(X_val,y_val),\"\\n\",\n",
        "      \"rf validation roc_auc_score :\", roc_auc_score(y_val,rf.predict(X_val)),\"\\n\",\n",
        "      \"xgb train accuracy :\", xgb.score(X_train2,y_train2),\"\\n\",\n",
        "      \"xgb train roc_auc_score :\", roc_auc_score(y_train2,xgb.predict(X_train2)),\"\\n\",\n",
        "      \"xgb validation accuracy :\", xgb.score(X_val,y_val),\"\\n\",\n",
        "      \"xgb validation roc_auc_score :\", roc_auc_score(y_val,xgb.predict(X_val)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OqsuDnA5SHp",
        "outputId": "33830c53-b4ec-47bc-e405-b11a8588ccb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf train accuracy : 0.8041014168530947 \n",
            " rf train roc_auc_score : 0.6765769192801346 \n",
            " rf validation accuracy : 0.7755741127348643 \n",
            " rf validation roc_auc_score : 0.6291050117509479 \n",
            " xgb train accuracy : 0.8771812080536913 \n",
            " xgb train roc_auc_score : 0.7919421714984218 \n",
            " xgb validation accuracy : 0.756437021572721 \n",
            " xgb validation roc_auc_score : 0.6150014112959835\n"
          ]
        }
      ]
    }
  ]
}